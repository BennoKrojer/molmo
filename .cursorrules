# CLAUDE.md - Rules for AI Assistants

## At the Start of Every Chat

**Read these files to understand context:**
1. **README.md** - Project overview, setup, model configurations
2. **JOURNAL.md** - Last few days of entries (recent changes, bugs, fixes)
3. **paper/main.tex** - Abstract and intro (understand the research goals)
4. **SCHEMA_STANDARDIZATION.md** - JSON formats, display names (if working with data)

---

## ⚠️ THE THREE RULES ⚠️

**These are the most violated rules. Read them before EVERY significant action.**

### 1. EDIT, NEVER REWRITE
- **ALWAYS edit existing code, NEVER rewrite from scratch**
- Find the exact file/function, make surgical changes with Edit tool
- If you're about to write 50+ lines of new code doing something similar to existing code, STOP

### 2. VALIDATE DATA BEFORE PLOTTING
- Never trust glob patterns - they can pick up wrong files (e.g., ablations)
- Check `paper_data_manifest.json` for expected values
- If a number looks different than expected, investigate before proceeding

### 3. COMMIT AND DOCUMENT IMMEDIATELY
- `git commit && git push` after every fix
- Update JOURNAL.md right after pushing
- Don't batch changes - commit as you go

---

## Code Changes

**Before changing any code:**
1. FIND the exact file that produces the current output
2. READ and understand it
3. EDIT only the specific lines needed (use Edit tool)
4. TEST that output matches except for your intended change

**For figures/plots:**
- Find the EXACT script that generated it (grep for filename)
- Make minimal edits to that script
- NEVER create "standalone" scripts with hardcoded data
- NEVER copy data values into new files

**Check existing scripts first:**
- Search for `run_all_*.sh`, `run_all_parallel_*.sh` before creating new ones
- These have established patterns for GPU management, error handling

**When adapting code for new models:**
- Verify EVERY detail matches original (layers, colors, fonts, markers)
- Explicitly state adherence: "Uses same markersize=8 as original"

---

## Data Loading

**Directory structure:**
```
analysis_results/llm_judge_{type}/
├── llm_judge_{model}_{layer}_*/   # Main results
└── ablations/                      # Ablation variants
    └── llm_judge_{model}_{layer}_*/
```

**Rules:**
1. NEVER use `**` glob without excluding `/ablations/`:
   ```python
   for f in path.glob("**/results_*.json"):
       if '/ablations/' in str(f):
           continue
   ```

2. Validate against `paper_data_manifest.json` golden values

3. When adding data to existing directories, check what scripts read from there

**What went wrong (2026-01-10):** Glob pattern picked up ablation files (42%) instead of main results (70%). Paper figure had wrong data.

---

## Execution

**Running commands:**
- Use: `source ../../env/bin/activate`
- Run long scripts in background
- If terminal returns empty: STOP, tell user (Cursor bug)

**Error handling:**
- Let errors fail loudly - no silent try-except
- Clean up debug prints after fixing

**Pre-flight checklist (before costly operations):**
1. Check existing `.sh` files for patterns
2. Grep codebase for similar code
3. Read argparse defaults
4. If ANY doubt, ASK user first

**LLM Judge API calls:**
- NEVER change `--api-provider` or `--api-model` without asking
- Check existing results naming (e.g., `gpt5` in directory names)

---

## Version Control

**Git workflow:**
- Commit and push after EVERY fix (don't wait)
- Check `git status` and file sizes before pushing (no files >100MB)
- Update JOURNAL.md immediately after pushing

**Paper repo (Overleaf sync):**
```bash
cd paper
git pull          # ALWAYS pull first!
# make changes
git add -A && git commit -m "msg" && git push
cd .. && git add paper && git commit -m "Update paper submodule" && git push
```

**JOURNAL.md:**
- Update after every significant change
- Format: `[YYYY-MM-DD] Brief description`
- Log: bug fixes, new scripts, results, git pushes

---

## Investigation

**When something seems wrong:**
1. STOP - don't patch the visible symptom
2. ASK WHY - trace back to data generation
3. VERIFY - test hypotheses with minimal examples
4. FIX ROOT - fix the source, not downstream

**Flag inconsistencies immediately:**
- Different layer counts across analysis types
- Missing data, unexpected numbers
- If numbers differ from expected, investigate WHY

---

## Quick Reference

**Regenerate demo viewer:**
```bash
python scripts/analysis/create_unified_viewer.py \
    --output-dir analysis_results/unified_viewer_lite \
    --num-images 10
```

**Sync to website:**
```bash
rsync -av --delete analysis_results/unified_viewer_lite/ website/vlm_interp_demo/
cd website && git add -A && git commit -m "Update demo" && git push
cd .. && git add website && git commit -m "Update website submodule" && git push
```

**Key paths:**
- Checkpoints: `molmo_data/checkpoints/`
- Analysis results: `analysis_results/`
- Contextual embeddings: `molmo_data/contextual_llm_embeddings_vg/`
- Viewer config: `scripts/analysis/viewer_models.json`

**Model info:**
- OLMo/LLaMA: 32 layers → analyze 0,1,2,4,8,16,24,30,31
- Qwen2: 28 layers → analyze 0,1,2,4,8,16,24,26,27
- Exception: `qwen2-7b_vit-l-14-336` has `_seed10` suffix
