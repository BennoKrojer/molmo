======================================================================
CONTEXTUAL NN (WITH IMAGE PRELOADING)
======================================================================
Checkpoint: molmo_data/checkpoints/train_mlp-only_pixmo_cap_resize_llama3-8b_vit-l-14-336/step12000-unsharded
Contextual dir: molmo_data/contextual_llm_embeddings_vg/meta-llama_Meta-Llama-3-8B
Visual layers: [0, 1, 16, 2, 24, 30, 31, 4, 8]
Contextual layers: [1, 2, 4, 8, 16, 24, 30, 31]
Images: 36 (indices: [100, 102, 108, 109, 119]...)
Total forward passes: 8 caches × 36 images = 288

======================================================================
LOADING MODEL
======================================================================
  Loading weights...
  Moving to GPU (fp16)...
✓ Model loaded in 253.5s

======================================================================
PRELOADING IMAGES TO GPU
======================================================================
  Loading 36 images directly to GPU...
    0/36 (image 100)...
    10/36 (image 155)...
    20/36 (image 234)...
    30/36 (image 284)...
✓ Images preloaded in 1.7s (21.2 img/s)

======================================================================
CONTEXTUAL LAYER 1 (1/8)
======================================================================
  Loading cache to GPU... Traceback (most recent call last):
  File "/home/nlp/users/bkroje/vl_embedding_spaces/third_party/molmo/scripts/analysis/contextual_nearest_neighbors_allLayers_singleGPU.py", line 455, in <module>
    main()
  File "/home/nlp/users/bkroje/vl_embedding_spaces/third_party/molmo/scripts/analysis/contextual_nearest_neighbors_allLayers_singleGPU.py", line 288, in main
    embeddings = cache_data['embeddings'].to(device)  # Move to GPU!
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 6.37 GiB. GPU 
